{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhSdUGu7Cf46"
      },
      "source": [
        "This notebook builds and evaluates a binary image classification model using a pretrained VIT on chest X-ray images to detect pneumonia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQdJ0z8rC8xP"
      },
      "source": [
        "#**Downloading Dataset From Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGM8TfmhE7B1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtNsC_GaFcF3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Make Kaggle folder and move file\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/kaggle.json\n",
        "\n",
        "# Set permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wft4HBPRE9lM"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf8gWAjFFAV5"
      },
      "outputs": [],
      "source": [
        "!unzip chest-xray-pneumonia.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyWrUst3DFxM"
      },
      "source": [
        "#**Installing Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TALWrkG2FDID"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision transformers datasets\n",
        "!pip install mlflow\n",
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEZhpZ1HDX85"
      },
      "source": [
        "#**Hugging Face Authentication**\n",
        "\n",
        "To access models and datasets hosted on the Hugging Face Hub, we need to authenticate using a personal access token (PAT). The following code logs you into the Hugging Face Hub using your token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgVJHRdHFGue"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JULXXPruD3TE"
      },
      "source": [
        " #**Vision Transformer (ViT) Setup for Image Classification**\n",
        "\n",
        "This code loads a pre-trained Vision Transformer (ViT) model from Hugging Face for binary image classification.\n",
        "\n",
        "- `ViTImageProcessor`: Prepares input images for the model.\n",
        "- `ViTForImageClassification`: Loads the ViT model.\n",
        "- `num_labels=2`: Sets it up for two-class classification.\n",
        "- `ignore_mismatched_sizes=True`: Allows changing the output layer to match our task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ7FK9PqFJvg"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import torch\n",
        "model_name = 'google/vit-base-patch16-224'\n",
        "processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFOHhNn9EJP3"
      },
      "source": [
        "#**Training Setup for ViT Model**\n",
        "\n",
        "- **Device Selection**: Uses GPU (`cuda`) if available, otherwise CPU.\n",
        "- **Image Transformations**: Resizes images to 224Ã—224, normalizes using ViT's expected mean/std.\n",
        "- **Dataset Loading**: Loads training, validation, and test images from folders.\n",
        "- **DataLoaders**: Batches the data and shuffles the training set.\n",
        "- **Loss Function**: Uses `CrossEntropyLoss` for classification.\n",
        "- **Optimizer**: Uses `AdamW` optimizer with a learning rate of `5e-5`.\n",
        "\n",
        "This setup prepares the data and model for training on chest X-ray images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwOoO58_FN_7"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
        "])\n",
        "train_data = datasets.ImageFolder(root=\"/content/chest_xray/chest_xray/train\", transform=transform)\n",
        "val_data   = datasets.ImageFolder(root=\"/content/chest_xray/chest_xray/val\", transform=transform)\n",
        "test_data  = datasets.ImageFolder(root=\"/content/chest_xray/chest_xray/test\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrN9c8lkElqV"
      },
      "source": [
        "#**Training the Vision Transformer (ViT) Model on Chest X-Ray Images**\n",
        "This code trains a Vision Transformer (ViT) model for 5 epochs on a chest X-ray image dataset. It uses a DataLoader to feed batches of images and labels to the model. For each batch, the model predicts outputs, computes the cross-entropy loss, performs backpropagation, and updates the model weights using the AdamW optimizer. After each epoch, it calculates and prints the average training loss and accuracy. The model is set to run on GPU if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBqIRFi8FRy4"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(pixel_values=images).logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100. * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXdNzvvyEuaQ"
      },
      "source": [
        "#**Saving Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDNGyrYWFUgA"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"vit_chest_model.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDdSfxU0EyuF"
      },
      "source": [
        "#**Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1g85GpIFWXz"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def predict_image(image_path, model, processor, device):\n",
        "    model.eval()\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_class = logits.argmax(-1).item()\n",
        "\n",
        "    return predicted_class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVKd5USvFY0Q"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/NormalXray.png\"\n",
        "predicted_class = predict_image(image_path, model, processor, device)\n",
        "class_names = train_data.classes\n",
        "print(f\"Predicted class: {class_names[predicted_class]}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
